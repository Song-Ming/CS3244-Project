{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dacfff18-b56d-47cc-8021-86b8f8941c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchinfo as info\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision.transforms import functional\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009fad0a-1e6e-492d-894b-d7c60e027a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a30476-d84d-4454-b282-1c16ad69849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790544f-fb7d-45d9-86b4-8cb420f61398",
   "metadata": {},
   "source": [
    "## Import Swin_V2 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b99fd7-d9af-4281-af60-0f49ed07b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import swin_v2_b, Swin_V2_B_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9b2801-09fd-44b7-90ae-aa2b11d48167",
   "metadata": {},
   "outputs": [],
   "source": [
    "swin_model = swin_v2_b(weights=Swin_V2_B_Weights.DEFAULT).to(device)\n",
    "preprocess = Swin_V2_B_Weights.DEFAULT.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2a411381-06bd-40f6-b2e8-609b9bf705bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageClassification(\n",
       "    crop_size=[256]\n",
       "    resize_size=[272]\n",
       "    mean=[0.485, 0.456, 0.406]\n",
       "    std=[0.229, 0.224, 0.225]\n",
       "    interpolation=InterpolationMode.BICUBIC\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0dc49c-a3a2-45e5-be4a-492c7f10d45b",
   "metadata": {},
   "source": [
    "## Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67bfc83f-fb88-43c1-911c-74905af090bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Class representing a set\n",
    "class WeedsDataset(Dataset):\n",
    "    def __init__(self, labels, img_dir, transform = None):\n",
    "        self.labels = pd.read_csv(labels)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.classes = self.labels[['Label','Species']].drop_duplicates().sort_values(by = 'Label').reset_index(drop = True)['Species']\n",
    "        self.data = []\n",
    "        self.train = []\n",
    "        self.validation = []\n",
    "        self.test = []\n",
    "        \n",
    "    # Load entire dataset into memory\n",
    "    def __loaddata__(self):\n",
    "        for row in self.labels.itertuples():\n",
    "            filename = row.Filename\n",
    "            label = torch.tensor(row.Label)\n",
    "            img_path = os.path.join(self.img_dir, filename)\n",
    "            image = self.transform(torchvision.io.read_image(img_path))\n",
    "            self.data.append([image,label])\n",
    "        del self.labels\n",
    "        print('Data has been loaded')\n",
    "\n",
    "    # Split into train/validation/test\n",
    "    def __split__(self):\n",
    "        random.shuffle(self.data)\n",
    "        n = len(self.data)\n",
    "        n_train = round(n * 0.8)\n",
    "        n_valid = round(n * 0.1)\n",
    "        \n",
    "        self.train = self.data[:n_train]\n",
    "        self.valid = self.data[n_train:n_train + n_valid]\n",
    "        self.test = self.data[n_train + n_valid:]\n",
    "        del self.data\n",
    "        \n",
    "        print('Data has been split')\n",
    "        print('Size of training set is {}'.format(len(self.train)))\n",
    "        print('Size of validation set is {}'.format(len(self.valid)))\n",
    "        print('Size of test set is {}'.format(len(self.test)))\n",
    "\n",
    "    # Augment with rotations and gaussian noise\n",
    "    def __augment__(self, frac):\n",
    "        n = round(len(self.train) * frac / 5)\n",
    "        rotate_90 = random.sample(self.train, n)\n",
    "        for row in rotate_90:\n",
    "            image = row[0]\n",
    "            row[0] = functional.rotate(image, 90)\n",
    "        rotate_180 = random.sample(self.train, n)\n",
    "        for row in rotate_180:\n",
    "            image = row[0]\n",
    "            row[0] = functional.rotate(image, 180)\n",
    "        rotate_270 = random.sample(self.train,n)\n",
    "        for row in rotate_270:\n",
    "            image = row[0]\n",
    "            row[0] = functional.rotate(image, 270)\n",
    "        self.train += rotate_90 + rotate_180 + rotate_270\n",
    "        gaussian = v2.GaussianNoise(0,0.08,False)\n",
    "        noise = random.sample(self.train, 2*n)\n",
    "        for row in noise:\n",
    "            image = row[0]\n",
    "            row[0] = gaussian(image)\n",
    "        self.train += noise\n",
    "        \n",
    "        print('Data has been augmented')\n",
    "        print('Size of training set is {}'.format(len(self.train)))\n",
    "        \n",
    "    # Get item from sets, format is (image,label)\n",
    "    def __getitem__(self, idx, split):\n",
    "        if split == 'train':\n",
    "            item = self.train[idx]\n",
    "        elif split == 'valid':\n",
    "            item = self.valid[idx]\n",
    "        elif split == 'test':\n",
    "            item = self.test[idx]\n",
    "        return item[0], item[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd999b99-02f7-4403-be23-349c41b8749f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been loaded\n",
      "Data has been split\n",
      "Size of training set is 14007\n",
      "Size of validation set is 1751\n",
      "Size of test set is 1751\n",
      "Data has been augmented\n",
      "Size of training set is 21012\n"
     ]
    }
   ],
   "source": [
    "# Run functions to load and process data\n",
    "weeds = WeedsDataset(rf'{wd}\\labels.csv', rf'{wd}\\images', preprocess)\n",
    "weeds.__loaddata__()\n",
    "weeds.__split__()\n",
    "weeds.__augment__(0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f2277d8-dcef-4aa8-974f-c722af4be2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to convert the label back into the class\n",
    "def convert_label(label, dataset):\n",
    "    return dataset.classes[label.item()]\n",
    "\n",
    "def convert_labels(labels,dataset):\n",
    "    lst = []\n",
    "    for label in labels:\n",
    "        data_class = convert_label(label,dataset)\n",
    "        lst.append(data_class)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc68ac7-2023-4c93-9d91-f3b3e2f28c06",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "449cc24d-c853-480c-bf5d-6897bc849725",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sends image and label tensors to gpu\n",
    "def get_batch(dataset, current_index, batch_size):\n",
    "    images,labels = zip(*dataset[current_index:current_index+batch_size])\n",
    "    return torch.stack(images, dim = 0).to(device), torch.stack(labels).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "34bdffe8-2ea1-4c78-b6ff-0efcbc2d7570",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that everything is working properly\n",
    "def matplotlib_imshow(img, one_channel=False):\n",
    "    if one_channel:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img / 2 + 0.5     # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "# Create a grid from the images and show them\n",
    "#images,labels = get_batch(weeds.train, 1000, 32)\n",
    "#img_grid = torchvision.utils.make_grid(images.cpu())\n",
    "#matplotlib_imshow(img_grid, one_channel=True)\n",
    "#print(convert_labels(labels.cpu(),weeds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7181340a-fd33-4dd8-bb35-9fcb14eb2d9d",
   "metadata": {},
   "source": [
    "## Replacing classification head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e8c9987-13f4-46b6-be18-8c514a06434b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in swin_model.parameters():\n",
    "    param.requires_grad = False\n",
    "layers = []\n",
    "layers.append(nn.Linear(in_features = 1024, out_features = 256, bias = True))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(in_features = 256, out_features = 9, bias = True))\n",
    "swin_model.head = nn.Sequential(*layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17ff415e-510c-49f4-b7eb-baaf55ffa701",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (1): ReLU()\n",
       "  (2): Linear(in_features=256, out_features=9, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swin_model.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be676306-7099-484a-9c63-7aea30ffd332",
   "metadata": {},
   "outputs": [],
   "source": [
    "#info.summary(swin_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8107d-61d6-4adf-9707-3a1b15906aa8",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f3460b1-2d9e-47dd-b181-664686497054",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = torch.nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(swin_model.parameters(), lr=0.0012, momentum = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08c99a1e-ef7c-431e-8bf8-8d74a0423903",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(batch_size):\n",
    "    batches = math.floor(len(weeds.train)/batch_size)\n",
    "    current_index = 0\n",
    "    running_loss = 0\n",
    "    random.shuffle(weeds.train)\n",
    "\n",
    "    for i in range(batches):\n",
    "        inputs,labels = get_batch(weeds.train, current_index, batch_size)\n",
    "        current_index += batch_size\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        outputs = swin_model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.cpu().item()\n",
    "\n",
    "    remainder = len(weeds.train)%batch_size\n",
    "    if remainder != 0:\n",
    "        inputs,labels = get_batch(weeds.train, current_index, batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = swin_model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.cpu().item()\n",
    "        batches += 1\n",
    "    \n",
    "    return running_loss/batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5e299c12-151b-457f-92cc-db73288bbc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(batch_size):\n",
    "    batches = math.floor(len(weeds.valid)/batch_size)\n",
    "    current_index = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i in range(batches):\n",
    "        inputs,labels = get_batch(weeds.valid, current_index, batch_size)\n",
    "        current_index += batch_size\n",
    "        output = swin_model(inputs)\n",
    "        running_loss += loss_fn(output, labels).cpu().item()\n",
    "\n",
    "    remainder = len(weeds.valid)%batch_size\n",
    "    if remainder != 0:\n",
    "        inputs,labels = get_batch(weeds.valid, current_index, batch_size)\n",
    "        output = swin_model(inputs)\n",
    "        running_loss += loss_fn(output, labels).cpu().item()\n",
    "        batches += 1\n",
    "    \n",
    "    return running_loss/batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "68045c7b-12be-4fa7-ac5a-e5e1e317affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs, batch_size, epoch_counter, folder_name, save):\n",
    "    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "    current_vloss = 0\n",
    "    start = time.perf_counter()\n",
    "    rounds = 1\n",
    "    \n",
    "    if not os.path.exists('{}\\{}'.format(wd,folder_name)):\n",
    "        os.makedirs('{}\\{}'.format(wd,folder_name))\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        print('EPOCH {}:'.format(epoch_counter + 1))\n",
    "        swin_model.train()\n",
    "        avg_loss = train_one_epoch(batch_size)\n",
    "        \n",
    "        swin_model.eval()\n",
    "        with torch.no_grad():\n",
    "            current_vloss = validate(batch_size)\n",
    "\n",
    "        # Only save last {save} rounds\n",
    "        if rounds + save >= epochs:\n",
    "            model_path = '{}\\model_{}_{}'.format(folder_name, timestamp, epoch_counter + 1)\n",
    "            torch.save(swin_model.state_dict(), model_path)\n",
    "        rounds += 1\n",
    "\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, current_vloss))\n",
    "        epoch_counter += 1\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print('Average time taken per epoch is {}s'.format((end - start)/epochs))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bde653c-6548-4fd2-96fa-6e763ae7d631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 1.3390585229402483 valid 0.9432550147175789\n",
      "EPOCH 2:\n",
      "LOSS train 0.8812311181263233 valid 0.7294931982954344\n",
      "EPOCH 3:\n",
      "LOSS train 0.723507198471921 valid 0.6235770475533273\n",
      "EPOCH 4:\n",
      "LOSS train 0.6283326989964465 valid 0.5532150583134757\n",
      "EPOCH 5:\n",
      "LOSS train 0.5730355395415616 valid 0.5062037453883224\n",
      "EPOCH 6:\n",
      "LOSS train 0.5310607932667268 valid 0.45651991789539653\n",
      "EPOCH 7:\n",
      "LOSS train 0.49577513542424473 valid 0.45451483585768276\n",
      "EPOCH 8:\n",
      "LOSS train 0.46962585737331464 valid 0.40802961587905884\n",
      "EPOCH 9:\n",
      "LOSS train 0.445639189483151 valid 0.4093300679491626\n",
      "EPOCH 10:\n",
      "LOSS train 0.42832543242572324 valid 0.38590303984367186\n",
      "EPOCH 11:\n",
      "LOSS train 0.41696283238942156 valid 0.36478071970244247\n",
      "EPOCH 12:\n",
      "LOSS train 0.403304303733017 valid 0.35426897183060646\n",
      "EPOCH 13:\n",
      "LOSS train 0.3862745182460391 valid 0.3463750943127606\n",
      "EPOCH 14:\n",
      "LOSS train 0.3713138032341796 valid 0.3371264518549045\n",
      "EPOCH 15:\n",
      "LOSS train 0.3663419714095757 valid 0.3275220168547498\n",
      "EPOCH 16:\n",
      "LOSS train 0.35631851770532386 valid 0.3181251415775882\n",
      "EPOCH 17:\n",
      "LOSS train 0.3433301923641683 valid 0.3171667779485385\n",
      "EPOCH 18:\n",
      "LOSS train 0.339511516046071 valid 0.31558634009626174\n",
      "EPOCH 19:\n",
      "LOSS train 0.326551393939806 valid 0.30258588182429474\n",
      "EPOCH 20:\n",
      "LOSS train 0.32188676609137845 valid 0.31236863653692937\n",
      "EPOCH 21:\n",
      "LOSS train 0.31858526787890956 valid 0.2991077785069744\n",
      "EPOCH 22:\n",
      "LOSS train 0.311104333050319 valid 0.28879069950845504\n",
      "EPOCH 23:\n",
      "LOSS train 0.3053496230809536 valid 0.28406271514379317\n",
      "EPOCH 24:\n",
      "LOSS train 0.297512863318031 valid 0.28612869005236363\n",
      "EPOCH 25:\n",
      "LOSS train 0.29496490047479185 valid 0.3051861592878898\n",
      "EPOCH 26:\n",
      "LOSS train 0.28900414707046224 valid 0.28253277153190637\n",
      "EPOCH 27:\n",
      "LOSS train 0.28488395612624934 valid 0.27797791863688165\n",
      "EPOCH 28:\n",
      "LOSS train 0.2783335058146871 valid 0.27384357977037627\n",
      "EPOCH 29:\n",
      "LOSS train 0.2750028821146403 valid 0.2772904019802809\n",
      "EPOCH 30:\n",
      "LOSS train 0.2731945138079537 valid 0.26456363768213326\n",
      "EPOCH 31:\n",
      "LOSS train 0.2683743003428407 valid 0.26788166915583944\n",
      "EPOCH 32:\n",
      "LOSS train 0.26280819867115973 valid 0.2716968541757928\n",
      "EPOCH 33:\n",
      "LOSS train 0.26214125977205266 valid 0.27587187476456165\n",
      "EPOCH 34:\n",
      "LOSS train 0.25317077471425586 valid 0.2537304637953639\n",
      "EPOCH 35:\n",
      "LOSS train 0.2541267609316634 valid 0.25145063404407764\n",
      "EPOCH 36:\n",
      "LOSS train 0.2507569074736921 valid 0.2579712493655582\n",
      "EPOCH 37:\n",
      "LOSS train 0.24720767849167 valid 0.25649010519393617\n",
      "EPOCH 38:\n",
      "LOSS train 0.2457796052505313 valid 0.24842061262784731\n",
      "EPOCH 39:\n",
      "LOSS train 0.23597041275042535 valid 0.25084978248924017\n",
      "EPOCH 40:\n",
      "LOSS train 0.23716605471495777 valid 0.2453389566184746\n",
      "EPOCH 41:\n",
      "LOSS train 0.23662371800730178 valid 0.25904769119289184\n",
      "EPOCH 42:\n",
      "LOSS train 0.23100599062556043 valid 0.25771009766807157\n",
      "EPOCH 43:\n",
      "LOSS train 0.22599660365393212 valid 0.24572176256010103\n",
      "EPOCH 44:\n",
      "LOSS train 0.22317122567153033 valid 0.24073612126004365\n",
      "EPOCH 45:\n",
      "LOSS train 0.2228610671862004 valid 0.24075537292648935\n",
      "EPOCH 46:\n",
      "LOSS train 0.22256399436263177 valid 0.23736371845006943\n",
      "EPOCH 47:\n",
      "LOSS train 0.21631294825156341 valid 0.23460834074972403\n",
      "EPOCH 48:\n",
      "LOSS train 0.20980762090365848 valid 0.23655879119825032\n",
      "EPOCH 49:\n",
      "LOSS train 0.2161245353856166 valid 0.23315080338054234\n",
      "EPOCH 50:\n",
      "LOSS train 0.21594588347929675 valid 0.2342542733790146\n",
      "Average time taken per epoch is 681.22002025s\n"
     ]
    }
   ],
   "source": [
    "train(50,50,0,'testmodel',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ebe99ef1-64e9-41ae-a3fe-ac89b3c32471",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 51:\n",
      "LOSS train 0.21138129660288965 valid 0.23275276894370714\n",
      "EPOCH 52:\n",
      "LOSS train 0.20749398246584483 valid 0.23221596748205936\n",
      "EPOCH 53:\n",
      "LOSS train 0.20058914164253766 valid 0.2224171869456768\n",
      "EPOCH 54:\n",
      "LOSS train 0.203108948662063 valid 0.23644539509485993\n",
      "EPOCH 55:\n",
      "LOSS train 0.20035356676068838 valid 0.2310625351448026\n",
      "EPOCH 56:\n",
      "LOSS train 0.19889075678027723 valid 0.22668670932115573\n",
      "EPOCH 57:\n",
      "LOSS train 0.19711799507257208 valid 0.23780708434060216\n",
      "EPOCH 58:\n",
      "LOSS train 0.19501334040330595 valid 0.22438563189158836\n",
      "EPOCH 59:\n",
      "LOSS train 0.19186643657944832 valid 0.22459907255445918\n",
      "EPOCH 60:\n",
      "LOSS train 0.19255517432886463 valid 0.2230653534902053\n",
      "EPOCH 61:\n",
      "LOSS train 0.19230194224792393 valid 0.22709874242233732\n",
      "EPOCH 62:\n",
      "LOSS train 0.18994908401136443 valid 0.2247819554629839\n",
      "EPOCH 63:\n",
      "LOSS train 0.18788126959618084 valid 0.21815137513395813\n",
      "EPOCH 64:\n",
      "LOSS train 0.1830734115828386 valid 0.22074600856285542\n",
      "EPOCH 65:\n",
      "LOSS train 0.1783893779982014 valid 0.21850013782063293\n",
      "EPOCH 66:\n",
      "LOSS train 0.17855436239400413 valid 0.22970268585615689\n",
      "EPOCH 67:\n",
      "LOSS train 0.18072609707819312 valid 0.2134412736243879\n",
      "EPOCH 68:\n",
      "LOSS train 0.18140006328174169 valid 0.21257525788516635\n",
      "EPOCH 69:\n",
      "LOSS train 0.17890157251488284 valid 0.2193729868158698\n",
      "EPOCH 70:\n",
      "LOSS train 0.17944843776860317 valid 0.21670279589792094\n",
      "EPOCH 71:\n",
      "LOSS train 0.17073198466289638 valid 0.21529412339441478\n",
      "EPOCH 72:\n",
      "LOSS train 0.16841956470913813 valid 0.21531652525946912\n",
      "EPOCH 73:\n",
      "LOSS train 0.1655895345735932 valid 0.21569872864832482\n",
      "EPOCH 74:\n",
      "LOSS train 0.16687957280605253 valid 0.2152354003240665\n",
      "EPOCH 75:\n",
      "LOSS train 0.16484875130221566 valid 0.21980267825225988\n",
      "Average time taken per epoch is 171.35602173599997s\n"
     ]
    }
   ],
   "source": [
    "# Run another 25 epochs\n",
    "train(25,50,50,'testmodel',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fef2fccc-7132-4dbd-92be-5f61d935b1bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 76:\n",
      "LOSS train 0.16367355166910097 valid 0.2128411340397886\n",
      "EPOCH 77:\n",
      "LOSS train 0.16301728439939844 valid 0.21041587779634735\n",
      "EPOCH 78:\n",
      "LOSS train 0.1630751442234972 valid 0.22084775999084943\n",
      "EPOCH 79:\n",
      "LOSS train 0.1587625771778638 valid 0.21552396984770894\n",
      "EPOCH 80:\n",
      "LOSS train 0.1595259168121141 valid 0.20760167340308222\n",
      "EPOCH 81:\n",
      "LOSS train 0.15745674547542443 valid 0.20671661055853796\n",
      "EPOCH 82:\n",
      "LOSS train 0.15689195425309366 valid 0.20413677550904039\n",
      "EPOCH 83:\n",
      "LOSS train 0.15562974101467825 valid 0.20506172221050495\n",
      "EPOCH 84:\n",
      "LOSS train 0.15468492368214062 valid 0.220046156590494\n",
      "EPOCH 85:\n",
      "LOSS train 0.15559231555376937 valid 0.2315680438057623\n",
      "Average time taken per epoch is 172.6834253799985s\n"
     ]
    }
   ],
   "source": [
    "# Run another 10 epochs\n",
    "train(10,50,75,'testmodel',10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0e8328e6-c01d-4177-ba40-dc9f06cde664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 83:\n",
      "LOSS train 0.14972701666969584 valid 0.20491910196789023\n",
      "EPOCH 84:\n",
      "LOSS train 0.14959352199350995 valid 0.2066789831992032\n",
      "EPOCH 85:\n",
      "LOSS train 0.14195913106486235 valid 0.20553429185464564\n",
      "EPOCH 86:\n",
      "LOSS train 0.14736420846590662 valid 0.20875638992422157\n",
      "EPOCH 87:\n",
      "LOSS train 0.14610925996388505 valid 0.20624750112700793\n",
      "EPOCH 88:\n",
      "LOSS train 0.14516572598943092 valid 0.2068008242123243\n",
      "EPOCH 89:\n",
      "LOSS train 0.1464302123805194 valid 0.20681307586427364\n",
      "EPOCH 90:\n",
      "LOSS train 0.14122015711212102 valid 0.20444773777853698\n",
      "Average time taken per epoch is 171.6681134999999s\n"
     ]
    }
   ],
   "source": [
    "# Epoch 82 has lowest validation loss so continue from there with lower lr and momentum\n",
    "swin_model.load_state_dict(torch.load('testmodel\\model_20250225_112924_82', weights_only = True))\n",
    "optimizer = torch.optim.SGD(swin_model.parameters(), lr=0.0008, momentum = 0.4)\n",
    "train(8,50,82,'testmodel',8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dfe8848-2e17-4e4e-a8dc-7c7a23f5c210",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 91:\n",
      "LOSS train 0.14382885376128618 valid 0.2046591496715943\n",
      "EPOCH 92:\n",
      "LOSS train 0.14452524261102256 valid 0.2064298023469746\n",
      "EPOCH 93:\n",
      "LOSS train 0.14626077479835503 valid 0.20892401467750055\n",
      "EPOCH 94:\n",
      "LOSS train 0.14717311182915457 valid 0.20388003129563811\n",
      "EPOCH 95:\n",
      "LOSS train 0.14596272116159742 valid 0.20464123661319414\n",
      "Average time taken per epoch is 165.95095590000273s\n"
     ]
    }
   ],
   "source": [
    "# Another 5 epochs\n",
    "train(5,50,90,'testmodel',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "eda472e9-bf4e-4ca3-8fd9-ad7cc85d2462",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 96:\n",
      "LOSS train 0.1446822808520103 valid 0.20132448068276668\n",
      "EPOCH 97:\n",
      "LOSS train 0.14158068325220122 valid 0.2035724569319023\n",
      "EPOCH 98:\n",
      "LOSS train 0.14351433894714238 valid 0.20157652236391893\n",
      "EPOCH 99:\n",
      "LOSS train 0.14470897748128395 valid 0.20637125166184786\n",
      "EPOCH 100:\n",
      "LOSS train 0.1420655709972291 valid 0.20792183633117625\n",
      "EPOCH 101:\n",
      "LOSS train 0.14546317078456317 valid 0.2028987623570073\n",
      "EPOCH 102:\n",
      "LOSS train 0.14408251759983298 valid 0.20585942750848416\n",
      "EPOCH 103:\n",
      "LOSS train 0.14432914624092413 valid 0.20309232489671558\n",
      "EPOCH 104:\n",
      "LOSS train 0.14650239195948966 valid 0.20421617870063832\n",
      "EPOCH 105:\n",
      "LOSS train 0.14196060319163453 valid 0.20999597037573242\n",
      "EPOCH 106:\n",
      "LOSS train 0.1420444050082614 valid 0.2078818557654611\n",
      "EPOCH 107:\n",
      "LOSS train 0.14309469083956755 valid 0.20478275088438144\n",
      "EPOCH 108:\n",
      "LOSS train 0.13905824877480996 valid 0.20949100140326968\n",
      "EPOCH 109:\n",
      "LOSS train 0.1403702573049946 valid 0.20431711139260894\n",
      "EPOCH 110:\n",
      "LOSS train 0.14525314658490893 valid 0.2042409760178998\n",
      "Average time taken per epoch is 175.89003384666674s\n"
     ]
    }
   ],
   "source": [
    "# Another 15 epochs\n",
    "train(15,50,95,'testmodel',15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83d054e7-d169-4b37-8a48-e4fece989e8c",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 97:\n",
      "LOSS train 0.14231866737938267 valid 0.20359141475960818\n",
      "EPOCH 98:\n",
      "LOSS train 0.14646978036560243 valid 0.20504553794550398\n",
      "EPOCH 99:\n",
      "LOSS train 0.14750776579714162 valid 0.2046950082035942\n",
      "EPOCH 100:\n",
      "LOSS train 0.1424761791702475 valid 0.20380187580465442\n",
      "EPOCH 101:\n",
      "LOSS train 0.14044551499577287 valid 0.20409172483616406\n",
      "EPOCH 102:\n",
      "LOSS train 0.13970945496775758 valid 0.20454917751097432\n",
      "EPOCH 103:\n",
      "LOSS train 0.14664217901378515 valid 0.20606204584085694\n",
      "EPOCH 104:\n",
      "LOSS train 0.14437565368748406 valid 0.20615295729496413\n",
      "EPOCH 105:\n",
      "LOSS train 0.14174389667508155 valid 0.20559932613590112\n",
      "EPOCH 106:\n",
      "LOSS train 0.14457347820515162 valid 0.2044525071590518\n",
      "EPOCH 107:\n",
      "LOSS train 0.14289272550024498 valid 0.20541364148569605\n",
      "EPOCH 108:\n",
      "LOSS train 0.14332885559727915 valid 0.20528541850702217\n",
      "EPOCH 109:\n",
      "LOSS train 0.144936253402975 valid 0.20464071342980283\n",
      "EPOCH 110:\n",
      "LOSS train 0.1417920665501345 valid 0.20263445753759393\n",
      "Average time taken per epoch is 159.89958819285883s\n"
     ]
    }
   ],
   "source": [
    "# Lower lr further from epoch 96\n",
    "swin_model.load_state_dict(torch.load('testmodel\\model_20250225_123744_96', weights_only = True))\n",
    "optimizer = torch.optim.SGD(swin_model.parameters(), lr=0.0004, momentum = 0.2)\n",
    "train(14,50,96,'testmodel',14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77adee-efc7-4d8c-8c40-68ecd19c2110",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5be5cb-5ba5-4a37-84ba-10c2de147534",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Lowest validation loss is 0.20132448068276668 at epoch 96"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8c14e663-8902-476c-891a-70bddad2430d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swin_model.load_state_dict(torch.load('testmodel\\model_20250225_123744_96', weights_only = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d2619715-3bf2-450a-8c14-4e7faa2ac5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(batch_size):\n",
    "    start = time.perf_counter()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    batches = math.floor(len(weeds.test)/batch_size)\n",
    "    current_index = 0\n",
    "    \n",
    "    for i in range(batches):\n",
    "        inputs,labels = get_batch(weeds.test, current_index, batch_size)\n",
    "        current_index += batch_size\n",
    "        prediction = torch.argmax(swin_model(inputs), dim = 1)\n",
    "        correct += sum(prediction == labels).cpu().item()\n",
    "        total += batch_size\n",
    "\n",
    "    remainder = len(weeds.test)%batch_size\n",
    "    if remainder != 0:\n",
    "        inputs,labels = get_batch(weeds.test, current_index, remainder)\n",
    "        prediction = torch.argmax(swin_model(inputs), dim = 1)\n",
    "        correct += sum(prediction == labels).cpu().item()\n",
    "        total += remainder\n",
    "\n",
    "    accuracy = 100*correct/total\n",
    "    print ('Accuracy is {}%'.format(accuracy))\n",
    "    end = time.perf_counter()\n",
    "    print('Time taken is {}'.format(end-start))\n",
    "    \n",
    "    return "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "191d8094-cd71-4366-b506-ab81b73c70df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy is 93.60365505425472%\n",
      "Time taken is 12.76658049999969\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    swin_model.eval()\n",
    "    evaluate(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19dd7973-1d8d-40b2-a5f5-a581786f5d89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy is 93.6%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49e72d4c-a750-4ca6-81ce-8784c082b6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(swin_model, 'trained_model\\weedsv2.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0ca8e83-1b07-4ff9-81ae-40871c5fa2bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dacfff18-b56d-47cc-8021-86b8f8941c67",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import gc\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchinfo as info\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.transforms.functional as functional\n",
    "from torchvision.transforms import v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "009fad0a-1e6e-492d-894b-d7c60e027a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "75a30476-d84d-4454-b282-1c16ad69849d",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1790544f-fb7d-45d9-86b4-8cb420f61398",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80b99fd7-d9af-4281-af60-0f49ed07b9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import swin_v2_t, Swin_V2_T_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a9b2801-09fd-44b7-90ae-aa2b11d48167",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = swin_v2_t(weights=Swin_V2_T_Weights.DEFAULT).to(device)\n",
    "process = Swin_V2_T_Weights.DEFAULT.transforms()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "958d5aad-f846-4847-86ad-9a1519cab348",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "layers = []\n",
    "layers.append(nn.Linear(in_features = 768, out_features = 256, bias = True))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(in_features = 256, out_features = 9, bias = True))\n",
    "model.head = nn.Sequential(*layers).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce0dc49c-a3a2-45e5-be4a-492c7f10d45b",
   "metadata": {},
   "source": [
    "## Load and Process Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "67bfc83f-fb88-43c1-911c-74905af090bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeedsDataset():\n",
    "    def __init__(self, labels, img_dir, transform = None):\n",
    "        self.labels = pd.read_csv(labels)\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "        self.classes = self.labels[['Label','Species']].drop_duplicates().sort_values(by = 'Label').reset_index(drop = True)['Species']\n",
    "        self.data = []\n",
    "        self.train = []\n",
    "        self.validation = []\n",
    "        self.test = []\n",
    "        \n",
    "    # Load entire dataset into memory\n",
    "    def __loaddata__(self):\n",
    "        for row in self.labels.itertuples():\n",
    "            filename = row.Filename\n",
    "            label = torch.tensor(row.Label)\n",
    "            img_path = os.path.join(self.img_dir, filename)\n",
    "            image = torchvision.io.read_image(img_path)\n",
    "            self.data.append([image,label])\n",
    "        del self.labels\n",
    "        print('Data has been loaded')\n",
    "\n",
    "    # Split into train/validation/test\n",
    "    def __split__(self):\n",
    "        random.shuffle(self.data)\n",
    "        n = len(self.data)\n",
    "        n_train = round(n * 0.8)\n",
    "        n_valid = round(n * 0.1)\n",
    "        \n",
    "        self.train = self.data[:n_train]\n",
    "        self.valid = self.data[n_train:n_train + n_valid]\n",
    "        self.test = self.data[n_train + n_valid:]\n",
    "        del self.data\n",
    "        gc.collect()\n",
    "        \n",
    "        print('Data has been split')\n",
    "        print('Size of training set is {}'.format(len(self.train)))\n",
    "        print('Size of validation set is {}'.format(len(self.valid)))\n",
    "        print('Size of test set is {}'.format(len(self.test)))\n",
    "\n",
    "    # Augment training data\n",
    "    def __augment__(self, frac):\n",
    "        aug = []\n",
    "        color_jitter = transforms.ColorJitter(brightness = 0.3, contrast = 0.2, saturation = 0.3, hue = 0.0)\n",
    "        n = round(len(self.train) * frac / 3)\n",
    "        \n",
    "        rotate_90 = random.sample(self.train, n)\n",
    "        for row in rotate_90:\n",
    "            image = row[0].clone()\n",
    "            image = transforms.functional.rotate(image, 90)\n",
    "            image = color_jitter(image)\n",
    "            row[0] = image\n",
    "        \n",
    "        rotate_180 = random.sample(self.train, n)\n",
    "        for row in rotate_180:\n",
    "            image = row[0].clone()\n",
    "            image = transforms.functional.rotate(image, 180)\n",
    "            image = color_jitter(image)\n",
    "            row[0] = image\n",
    "        \n",
    "        rotate_270 = random.sample(self.train, n)\n",
    "        for row in rotate_270:\n",
    "            image = row[0].clone()\n",
    "            image = transforms.functional.rotate(image, 270)\n",
    "            image = color_jitter(image)\n",
    "            row[0] = image\n",
    "     \n",
    "        self.train += rotate_90 + rotate_180 + rotate_270  \n",
    "        print('Data has been augmented')\n",
    "        print('Size of training set is {}'.format(len(self.train)))\n",
    "\n",
    "    # Apply model transformation\n",
    "    def __apply__(self):\n",
    "        for i in range(len(self.train)):\n",
    "            self.train[i][0] = self.transform(self.train[i][0])\n",
    "        for i in range(len(self.valid)):\n",
    "            self.valid[i][0] = self.transform(self.valid[i][0])\n",
    "        for i in range(len(self.test)):\n",
    "            self.test[i][0] = self.transform(self.test[i][0]) \n",
    "        print('Data has been transformed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd999b99-02f7-4403-be23-349c41b8749f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been loaded\n",
      "Data has been split\n",
      "Size of training set is 14007\n",
      "Size of validation set is 1751\n",
      "Size of test set is 1751\n",
      "Data has been augmented\n",
      "Size of training set is 22410\n",
      "Data has been transformed\n"
     ]
    }
   ],
   "source": [
    "# Run functions to load and process data\n",
    "weeds = WeedsDataset(rf'{wd}\\labels.csv', rf'{wd}\\images', process)\n",
    "weeds.__loaddata__()\n",
    "weeds.__split__()\n",
    "weeds.__augment__(0.6)\n",
    "weeds.__apply__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8107d-61d6-4adf-9707-3a1b15906aa8",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5e299c12-151b-457f-92cc-db73288bbc34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(dataset, current_index, batch_size):\n",
    "    images,labels = zip(*dataset[current_index:current_index+batch_size])\n",
    "    return torch.stack(images, dim = 0).to(device), torch.stack(labels).to(device)\n",
    "    \n",
    "def train_one_epoch(model, dataset, batch_size):\n",
    "    batches = math.floor(len(dataset.train)/batch_size)\n",
    "    current_index = 0\n",
    "    running_loss = 0\n",
    "    random.shuffle(dataset.train)\n",
    "\n",
    "    for i in range(batches):\n",
    "        inputs,labels = get_batch(dataset.train, current_index, batch_size)\n",
    "        current_index += batch_size\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.cpu().item()\n",
    "\n",
    "    remainder = len(dataset.train)%batch_size\n",
    "    if remainder != 0:\n",
    "        inputs,labels = get_batch(dataset.train, current_index, batch_size)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.cpu().item()\n",
    "        batches += 1\n",
    "    \n",
    "    return running_loss/batches\n",
    "\n",
    "def validate(model, dataset, batch_size):\n",
    "    batches = math.floor(len(dataset.valid)/batch_size)\n",
    "    current_index = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i in range(batches):\n",
    "        inputs,labels = get_batch(dataset.valid, current_index, batch_size)\n",
    "        current_index += batch_size\n",
    "        output = model(inputs)\n",
    "        running_loss += loss_fn(output, labels).cpu().item()\n",
    "\n",
    "    remainder = len(dataset.valid)%batch_size\n",
    "    if remainder != 0:\n",
    "        inputs,labels = get_batch(dataset.valid, current_index, batch_size)\n",
    "        output = model(inputs)\n",
    "        running_loss += loss_fn(output, labels).cpu().item()\n",
    "        batches += 1\n",
    "    \n",
    "    return running_loss/batches\n",
    "\n",
    "def train(epochs, model, dataset, batch_size, folder_name, epoch_number, save):\n",
    "    best_vloss = 1000\n",
    "    current_vloss = 0\n",
    "    epoch_counter = epoch_number + 1\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    if not os.path.exists('{}\\{}'.format(wd,folder_name)):\n",
    "        os.makedirs('{}\\{}'.format(wd,folder_name))\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        print('EPOCH {}:'.format(epoch_counter))\n",
    "        model.train()\n",
    "        avg_loss = train_one_epoch(model, dataset, batch_size)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            current_vloss = validate(model, dataset, batch_size)\n",
    "\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, current_vloss))\n",
    "        if current_vloss <= best_vloss:\n",
    "                best_vloss = current_vloss\n",
    "                print('New best validation loss')\n",
    "\n",
    "        print('Lr is currently {}'.format(lr_scheduler.get_last_lr()))\n",
    "        lr_scheduler.step(current_vloss)\n",
    "\n",
    "        if epoch_counter > epochs - save:\n",
    "            model_path = '{}\\model_{}'.format(folder_name, epoch_counter)\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            \n",
    "        epoch_counter += 1\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print('Average time taken per epoch is {}s'.format((end - start)/epochs))\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "68045c7b-12be-4fa7-ac5a-e5e1e317affd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula for F1: (2 * FP) / (2 * TP + FP + FN) OR 2 * (Precision * Recall) / (Precision + Recall)\n",
    "# Formula for Precision: TP / (TP + FP)\n",
    "# Formula for Recall: TP / (TP + FN)\n",
    "def metrics(TP,FP,FN):\n",
    "    if TP > 0:\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        F1  = TP / (TP + 0.5 * (FP + FN))\n",
    "    else:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        F1  = 0\n",
    "    return precision, recall, F1\n",
    "    \n",
    "def evaluate(model, dataset, batch_size):\n",
    "    start = time.perf_counter()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    batches = math.floor(len(dataset.test) / batch_size)\n",
    "    current_index = 0\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for i in range(batches):\n",
    "        inputs, labels = get_batch(dataset.test, current_index, batch_size)\n",
    "        current_index += batch_size\n",
    "        prediction = torch.argmax(model(inputs), dim=1)\n",
    "        \n",
    "        correct += sum(prediction == labels).item()\n",
    "        total += batch_size\n",
    "\n",
    "        all_preds.extend(prediction.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    remainder = len(dataset.test) % batch_size\n",
    "    if remainder != 0:\n",
    "        inputs, labels = get_batch(dataset.test, current_index, remainder)\n",
    "        prediction = torch.argmax(model(inputs), dim=1)\n",
    "        \n",
    "        correct += sum(prediction == labels).item()\n",
    "        total += remainder\n",
    "\n",
    "        all_preds.extend(prediction.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Compute Metrics for individual classes\n",
    "    num_classes = len(dataset.classes) \n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds, labels=np.arange(num_classes))\n",
    "    print(conf_matrix)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        TP = conf_matrix[i, i]  # True Positives\n",
    "        FP = np.sum(conf_matrix[:, i]) - TP  # False Positives\n",
    "        FN = np.sum(conf_matrix[i, :]) - TP  # False Negatives\n",
    "        precision,recall,F1 = metrics(TP, FP, FN)\n",
    "        print(f\"Precision for class {dataset.classes[i]}: {precision:.4f}\")\n",
    "        print(f\"Recall for class {dataset.classes[i]}: {recall:.4f}\")\n",
    "        print(f\"F1-score for class {dataset.classes[i]}: {F1:.4f}\")\n",
    "    print('Total Accuracy is {}%'.format(accuracy))\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    print('Time taken is {}'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8577d8-1d26-4b6a-9c8b-7e16335069f9",
   "metadata": {},
   "source": [
    "## Training with only classifier unfrozen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f73b171-8ffe-4d09-ae58-2462d99cf720",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.6)\n",
    "lr_scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.5, patience = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a8c84aa-7c06-4179-980e-0bb63ee85038",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 1.2629476581225152 valid 0.8630113022194968\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 2:\n",
      "LOSS train 0.917862267828731 valid 0.6485434431168768\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 3:\n",
      "LOSS train 0.8140256278100683 valid 0.5781519677903917\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 4:\n",
      "LOSS train 0.7569267750450126 valid 0.5418662387463782\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 5:\n",
      "LOSS train 0.7132276187760793 valid 0.4848803004456891\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 6:\n",
      "LOSS train 0.6868865117596624 valid 0.4489338969190915\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 7:\n",
      "LOSS train 0.6660087191580664 valid 0.45414743738041985\n",
      "Lr is currently [0.01]\n",
      "EPOCH 8:\n",
      "LOSS train 0.6352423481261544 valid 0.3914952497515414\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 9:\n",
      "LOSS train 0.6200557996939976 valid 0.3914130994429191\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 10:\n",
      "LOSS train 0.6043372343902067 valid 0.37813184534509975\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 11:\n",
      "LOSS train 0.5935565527271321 valid 0.3672907091677189\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 12:\n",
      "LOSS train 0.5673698988019226 valid 0.35404348963250715\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 13:\n",
      "LOSS train 0.5613801006086685 valid 0.366674289935165\n",
      "Lr is currently [0.01]\n",
      "EPOCH 14:\n",
      "LOSS train 0.5544901379697307 valid 0.33497448115506107\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 15:\n",
      "LOSS train 0.5354957018039275 valid 0.33944492207633126\n",
      "Lr is currently [0.01]\n",
      "EPOCH 16:\n",
      "LOSS train 0.5312124886332217 valid 0.38515249898450243\n",
      "Lr is currently [0.01]\n",
      "EPOCH 17:\n",
      "LOSS train 0.5214100250754431 valid 0.33785603423085475\n",
      "Lr is currently [0.01]\n",
      "EPOCH 18:\n",
      "LOSS train 0.5123784788998305 valid 0.3215043544769287\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 19:\n",
      "LOSS train 0.4991857020188546 valid 0.31755677284672856\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 20:\n",
      "LOSS train 0.4900926849026988 valid 0.309237237709264\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 21:\n",
      "LOSS train 0.48789727983203923 valid 0.308314042372836\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 22:\n",
      "LOSS train 0.4811303606277585 valid 0.2962070566912492\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 23:\n",
      "LOSS train 0.47268789405944883 valid 0.29325140707401764\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 24:\n",
      "LOSS train 0.46937320914061403 valid 0.29620394082222545\n",
      "Lr is currently [0.01]\n",
      "EPOCH 25:\n",
      "LOSS train 0.4688825131391895 valid 0.2940365892524521\n",
      "Lr is currently [0.01]\n",
      "EPOCH 26:\n",
      "LOSS train 0.45147662774093433 valid 0.2827776410332363\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 27:\n",
      "LOSS train 0.4415157743644608 valid 0.30266108728634816\n",
      "Lr is currently [0.01]\n",
      "EPOCH 28:\n",
      "LOSS train 0.4401016429829969 valid 0.3018889944457139\n",
      "Lr is currently [0.01]\n",
      "EPOCH 29:\n",
      "LOSS train 0.43559519737494284 valid 0.2840636576163686\n",
      "Lr is currently [0.01]\n",
      "EPOCH 30:\n",
      "LOSS train 0.43458091967089935 valid 0.2776861535385251\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 31:\n",
      "LOSS train 0.4262995066780821 valid 0.2874840664509166\n",
      "Lr is currently [0.01]\n",
      "EPOCH 32:\n",
      "LOSS train 0.41799222271399933 valid 0.2866562885012374\n",
      "Lr is currently [0.01]\n",
      "EPOCH 33:\n",
      "LOSS train 0.41152173179494245 valid 0.2729512798703379\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 34:\n",
      "LOSS train 0.40983938186829766 valid 0.261632533187771\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 35:\n",
      "LOSS train 0.4066579000057781 valid 0.2660820222356253\n",
      "Lr is currently [0.01]\n",
      "EPOCH 36:\n",
      "LOSS train 0.39997714723072497 valid 0.2632388264885069\n",
      "Lr is currently [0.01]\n",
      "EPOCH 37:\n",
      "LOSS train 0.3946133639273505 valid 0.2937780800356349\n",
      "Lr is currently [0.01]\n",
      "EPOCH 38:\n",
      "LOSS train 0.3956381030596444 valid 0.28053363671319353\n",
      "Lr is currently [0.01]\n",
      "EPOCH 39:\n",
      "LOSS train 0.3818587167292236 valid 0.27962557829192114\n",
      "Lr is currently [0.01]\n",
      "EPOCH 40:\n",
      "LOSS train 0.3861865503485325 valid 0.27128355466346776\n",
      "Lr is currently [0.01]\n",
      "EPOCH 41:\n",
      "LOSS train 0.3811460959088298 valid 0.2746811552723456\n",
      "Lr is currently [0.01]\n",
      "EPOCH 42:\n",
      "LOSS train 0.3774780651641582 valid 0.2542154638536481\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 43:\n",
      "LOSS train 0.36949068843853766 valid 0.25049833650054\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 44:\n",
      "LOSS train 0.362202528523974 valid 0.244359118960953\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 45:\n",
      "LOSS train 0.36142480489538614 valid 0.2549945367500186\n",
      "Lr is currently [0.01]\n",
      "EPOCH 46:\n",
      "LOSS train 0.3587041332288946 valid 0.2925681876432564\n",
      "Lr is currently [0.01]\n",
      "EPOCH 47:\n",
      "LOSS train 0.35469581108780907 valid 0.2774848150503304\n",
      "Lr is currently [0.01]\n",
      "EPOCH 48:\n",
      "LOSS train 0.34644445216071634 valid 0.25328495637384346\n",
      "Lr is currently [0.01]\n",
      "EPOCH 49:\n",
      "LOSS train 0.34329025105537975 valid 0.29133381037455464\n",
      "Lr is currently [0.01]\n",
      "EPOCH 50:\n",
      "LOSS train 0.34543809988318147 valid 0.25610531316811425\n",
      "Lr is currently [0.01]\n",
      "EPOCH 51:\n",
      "LOSS train 0.3441954800041853 valid 0.25337990432874197\n",
      "Lr is currently [0.01]\n",
      "EPOCH 52:\n",
      "LOSS train 0.34260101994719433 valid 0.2514886738887678\n",
      "Lr is currently [0.01]\n",
      "EPOCH 53:\n",
      "LOSS train 0.33506045787530914 valid 0.2575154764086215\n",
      "Lr is currently [0.01]\n",
      "EPOCH 54:\n",
      "LOSS train 0.3361471070345898 valid 0.2583509878281297\n",
      "Lr is currently [0.01]\n",
      "EPOCH 55:\n",
      "LOSS train 0.32997734841365856 valid 0.24483454144986658\n",
      "Lr is currently [0.01]\n",
      "EPOCH 56:\n",
      "LOSS train 0.32892721257523067 valid 0.26142000088131884\n",
      "Lr is currently [0.01]\n",
      "EPOCH 57:\n",
      "LOSS train 0.32461186994555796 valid 0.2509508541746375\n",
      "Lr is currently [0.01]\n",
      "EPOCH 58:\n",
      "LOSS train 0.32139418551279336 valid 0.2869881246652868\n",
      "Lr is currently [0.01]\n",
      "EPOCH 59:\n",
      "LOSS train 0.323418475023755 valid 0.24123725796946222\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 60:\n",
      "LOSS train 0.32350092379579565 valid 0.2467121912761488\n",
      "Lr is currently [0.01]\n",
      "EPOCH 61:\n",
      "LOSS train 0.3103907683777119 valid 0.2403732964659058\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 62:\n",
      "LOSS train 0.30995907423756436 valid 0.25506551505532116\n",
      "Lr is currently [0.01]\n",
      "EPOCH 63:\n",
      "LOSS train 0.31535354971819307 valid 0.2628871150744898\n",
      "Lr is currently [0.01]\n",
      "EPOCH 64:\n",
      "LOSS train 0.30650722426268995 valid 0.23577941637227517\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 65:\n",
      "LOSS train 0.3127587790578139 valid 0.2955323287492825\n",
      "Lr is currently [0.01]\n",
      "EPOCH 66:\n",
      "LOSS train 0.30507191300458525 valid 0.2407475061514156\n",
      "Lr is currently [0.01]\n",
      "EPOCH 67:\n",
      "LOSS train 0.3056511557712852 valid 0.23386029496840718\n",
      "New best validation loss\n",
      "Lr is currently [0.01]\n",
      "EPOCH 68:\n",
      "LOSS train 0.30109863142526494 valid 0.250766934438919\n",
      "Lr is currently [0.01]\n",
      "EPOCH 69:\n",
      "LOSS train 0.289043936388928 valid 0.2541440279843907\n",
      "Lr is currently [0.01]\n",
      "EPOCH 70:\n",
      "LOSS train 0.2954221256989944 valid 0.2475582144430114\n",
      "Lr is currently [0.01]\n",
      "EPOCH 71:\n",
      "LOSS train 0.29536496788130573 valid 0.2411266090089662\n",
      "Lr is currently [0.01]\n",
      "EPOCH 72:\n",
      "LOSS train 0.29050515865894627 valid 0.2891488594727384\n",
      "Lr is currently [0.01]\n",
      "EPOCH 73:\n",
      "LOSS train 0.2880868288648952 valid 0.23595838334747693\n",
      "Lr is currently [0.01]\n",
      "EPOCH 74:\n",
      "LOSS train 0.28303812708050213 valid 0.2445761745588647\n",
      "Lr is currently [0.01]\n",
      "EPOCH 75:\n",
      "LOSS train 0.28573485493726347 valid 0.237828286707453\n",
      "Lr is currently [0.01]\n",
      "EPOCH 76:\n",
      "LOSS train 0.28820871804033993 valid 0.25523044615692925\n",
      "Lr is currently [0.01]\n",
      "EPOCH 77:\n",
      "LOSS train 0.2819666411304527 valid 0.2445218382021671\n",
      "Lr is currently [0.01]\n",
      "EPOCH 78:\n",
      "LOSS train 0.28070356801384544 valid 0.24594082370458636\n",
      "Lr is currently [0.01]\n",
      "EPOCH 79:\n",
      "LOSS train 0.2764938067819069 valid 0.2503843980133145\n",
      "Lr is currently [0.01]\n",
      "EPOCH 80:\n",
      "LOSS train 0.2743376698220493 valid 0.24189715318142488\n",
      "Lr is currently [0.01]\n",
      "EPOCH 81:\n",
      "LOSS train 0.2776870450755801 valid 0.24194172826699084\n",
      "Lr is currently [0.01]\n",
      "EPOCH 82:\n",
      "LOSS train 0.27272212625645054 valid 0.24592418471972147\n",
      "Lr is currently [0.01]\n",
      "EPOCH 83:\n",
      "LOSS train 0.27022142107608854 valid 0.2429872459033504\n",
      "Lr is currently [0.01]\n",
      "EPOCH 84:\n",
      "LOSS train 0.25859657644329465 valid 0.23248264749094638\n",
      "New best validation loss\n",
      "Lr is currently [0.005]\n",
      "EPOCH 85:\n",
      "LOSS train 0.252742613120241 valid 0.2334727081502529\n",
      "Lr is currently [0.005]\n",
      "EPOCH 86:\n",
      "LOSS train 0.25484894075014014 valid 0.23236278761436957\n",
      "New best validation loss\n",
      "Lr is currently [0.005]\n",
      "EPOCH 87:\n",
      "LOSS train 0.25434145688147747 valid 0.23977733404091042\n",
      "Lr is currently [0.005]\n",
      "EPOCH 88:\n",
      "LOSS train 0.24835292824890406 valid 0.2346001896884344\n",
      "Lr is currently [0.005]\n",
      "EPOCH 89:\n",
      "LOSS train 0.2549284944655104 valid 0.26064075527635094\n",
      "Lr is currently [0.005]\n",
      "EPOCH 90:\n",
      "LOSS train 0.25244387768557447 valid 0.22358251145568728\n",
      "New best validation loss\n",
      "Lr is currently [0.005]\n",
      "EPOCH 91:\n",
      "LOSS train 0.2495218519378611 valid 0.23509973500687112\n",
      "Lr is currently [0.005]\n",
      "EPOCH 92:\n",
      "LOSS train 0.2484415980815091 valid 0.23223580707013347\n",
      "Lr is currently [0.005]\n",
      "EPOCH 93:\n",
      "LOSS train 0.24470859754390864 valid 0.2370311580566017\n",
      "Lr is currently [0.005]\n",
      "EPOCH 94:\n",
      "LOSS train 0.24622491297451055 valid 0.2396390111955245\n",
      "Lr is currently [0.005]\n",
      "EPOCH 95:\n",
      "LOSS train 0.24109667151303493 valid 0.23244965534670176\n",
      "Lr is currently [0.005]\n",
      "EPOCH 96:\n",
      "LOSS train 0.24507251167815086 valid 0.2588556429836899\n",
      "Lr is currently [0.005]\n",
      "EPOCH 97:\n",
      "LOSS train 0.2447947792642499 valid 0.2450753252164254\n",
      "Lr is currently [0.005]\n",
      "EPOCH 98:\n",
      "LOSS train 0.24193105113200994 valid 0.22259960456479652\n",
      "New best validation loss\n",
      "Lr is currently [0.005]\n",
      "EPOCH 99:\n",
      "LOSS train 0.23786296770142554 valid 0.23988674353394243\n",
      "Lr is currently [0.005]\n",
      "EPOCH 100:\n",
      "LOSS train 0.23852994102146685 valid 0.23492397151939157\n",
      "Lr is currently [0.005]\n",
      "Average time taken per epoch is 77.43422338000033s\n"
     ]
    }
   ],
   "source": [
    "train(100,model,weeds,50,'swin_t',0,50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e77adee-efc7-4d8c-8c40-68ecd19c2110",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3af2e86d-fe7d-4f3f-9467-55092b1539ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = os.path.join(wd,'swin_t','model_98')\n",
    "model.load_state_dict(torch.load(model_path, weights_only = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d546733-f8a5-4c65-9504-353ae40a7fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 90   1   0   0   0   0   1   9   5]\n",
      " [  2  89   1   0   1   0   1   1   5]\n",
      " [  1   0  96   1   0   0   0   0   0]\n",
      " [  1   1   0  85   1   0   1   0   8]\n",
      " [  0   0   1   2 109   0   0   0   4]\n",
      " [  0   0   1   0   0  90   0   0  11]\n",
      " [  0   0   0   0   0   0  83   0  11]\n",
      " [ 10   0   0   1   0   0   0  78   3]\n",
      " [  4   8   2   4  10   3   5   5 905]]\n",
      "Precision for class Chinee apple: 0.8333\n",
      "Recall for class Chinee apple: 0.8491\n",
      "F1-score for class Chinee apple: 0.8411\n",
      "Precision for class Lantana: 0.8990\n",
      "Recall for class Lantana: 0.8900\n",
      "F1-score for class Lantana: 0.8945\n",
      "Precision for class Parkinsonia: 0.9505\n",
      "Recall for class Parkinsonia: 0.9796\n",
      "F1-score for class Parkinsonia: 0.9648\n",
      "Precision for class Parthenium: 0.9140\n",
      "Recall for class Parthenium: 0.8763\n",
      "F1-score for class Parthenium: 0.8947\n",
      "Precision for class Prickly acacia: 0.9008\n",
      "Recall for class Prickly acacia: 0.9397\n",
      "F1-score for class Prickly acacia: 0.9198\n",
      "Precision for class Rubber vine: 0.9677\n",
      "Recall for class Rubber vine: 0.8824\n",
      "F1-score for class Rubber vine: 0.9231\n",
      "Precision for class Siam weed: 0.9121\n",
      "Recall for class Siam weed: 0.8830\n",
      "F1-score for class Siam weed: 0.8973\n",
      "Precision for class Snake weed: 0.8387\n",
      "Recall for class Snake weed: 0.8478\n",
      "F1-score for class Snake weed: 0.8432\n",
      "Precision for class Negative: 0.9506\n",
      "Recall for class Negative: 0.9567\n",
      "F1-score for class Negative: 0.9536\n",
      "Total Accuracy is 92.80411193603655%\n",
      "Time taken is 5.435044099984225\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    evaluate(model, weeds, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fee680-05cb-44cf-91fc-c53e8cb477fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

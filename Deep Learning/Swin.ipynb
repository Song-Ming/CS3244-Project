{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0d9aca3d-cb6f-4801-9f88-a1c3f43a0e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torchinfo as info\n",
    "import torchvision.transforms.v2 as v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7069ad6-8762-4612-9cd7-82e1a0a3915d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "set_seed(600)\n",
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0d754c8-3fde-4553-a8b9-d001b8e546af",
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = os.getcwd()\n",
    "labels_dir = os.path.join(wd,'Labels')\n",
    "img_dir = os.path.join(wd,'Sets')\n",
    "record_path = os.path.join(wd,'Records')\n",
    "model_path = os.path.join(wd,'Models')\n",
    "if not os.path.exists(record_path):\n",
    "    os.makedirs(record_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17a8b66-dbd7-4fd5-bd6e-1174c4b0d2b2",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ef5881e8-ed4f-4259-95f7-fd5cc952824b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.models import swin_s, Swin_S_Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bba08aef-f362-4541-83f2-7a65a8d6623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = swin_s(weights = Swin_S_Weights.IMAGENET1K_V1).to(device)\n",
    "transform = Swin_S_Weights.IMAGENET1K_V1.transforms()\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5adfb4b0-e729-4634-9b8c-6444abb33d6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "layers = []\n",
    "layers.append(nn.Linear(in_features = 768, out_features = 256, bias = True))\n",
    "layers.append(nn.Dropout(p = 0.15))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(in_features = 256, out_features = 256, bias = True))\n",
    "layers.append(nn.ReLU())\n",
    "layers.append(nn.Linear(in_features = 256, out_features = 9, bias = True))\n",
    "model.head = nn.Sequential(*layers).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28c79148-45a2-484e-83c8-4167816000ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "for param in model.features[7][0].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.features[7][1].parameters():\n",
    "    param.requires_grad = True\n",
    "for param in model.norm.parameters():\n",
    "    param.requires_grad = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc0d0eb-2fc3-438d-8393-552d8cdc4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#info.summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de01fe8-f450-4559-9bd3-d760900f1bfa",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15bcb2ee-cb99-46d3-8d46-2987a5579c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeedsDataset():\n",
    "    def __init__(self, labels_dir, img_dir, transform):\n",
    "        self.train_labels = pd.read_csv(os.path.join(labels_dir,'train.csv'))\n",
    "        self.valid_labels = pd.read_csv(os.path.join(labels_dir,'valid.csv'))\n",
    "        self.test_labels = pd.read_csv(os.path.join(labels_dir,'test.csv'))\n",
    "        self.img_dir = img_dir\n",
    "        self.classes = None\n",
    "        self.counts = {'train':{},'valid':{},'test':{}}\n",
    "        self.train = []\n",
    "        self.valid = []\n",
    "        self.test = []\n",
    "        self.augmented = []\n",
    "        self.transform = transform\n",
    "        \n",
    "    # Load dataset\n",
    "    def __loaddata__(self):\n",
    "        self.classes = self.train_labels[['Label','Class']].drop_duplicates().sort_values(by = 'Label').reset_index(drop = True)['Class']\n",
    "        for key in self.classes.keys():\n",
    "            self.counts['train'][key] = 0\n",
    "            self.counts['valid'][key] = 0\n",
    "            self.counts['test'][key] = 0\n",
    "\n",
    "        for row in self.train_labels.itertuples():\n",
    "            filename = row.Filename\n",
    "            label = row.Label\n",
    "            self.counts['train'][row.Label] += 1\n",
    "            img_path = os.path.join(self.img_dir,'train',filename)\n",
    "            image = torchvision.io.read_image(img_path)\n",
    "            self.train.append([image,label])   \n",
    "        for row in self.valid_labels.itertuples():\n",
    "            filename = row.Filename\n",
    "            label = row.Label\n",
    "            self.counts['valid'][row.Label] += 1\n",
    "            img_path = os.path.join(self.img_dir,'valid',filename)\n",
    "            image = torchvision.io.read_image(img_path)\n",
    "            self.valid.append([image,label])   \n",
    "        for row in self.test_labels.itertuples():\n",
    "            filename = row.Filename\n",
    "            label = row.Label\n",
    "            self.counts['test'][row.Label] += 1\n",
    "            img_path = os.path.join(self.img_dir,'test',filename)\n",
    "            image = torchvision.io.read_image(img_path)\n",
    "            self.test.append([image,label])\n",
    "\n",
    "        del self.train_labels,self.valid_labels,self.test_labels\n",
    "        print('Data has been loaded')\n",
    "\n",
    "    def __apply__(self):\n",
    "        for i in range(len(self.train)):\n",
    "            image = transform(self.train[i][0])\n",
    "            label = torch.tensor(self.train[i][1])\n",
    "            self.train[i] = [image,label]\n",
    "\n",
    "        for i in range(len(self.valid)):\n",
    "            image = transform(self.valid[i][0])\n",
    "            label = torch.tensor(self.valid[i][1])\n",
    "            self.valid[i] = [image,label]\n",
    "\n",
    "        for i in range(len(self.test)):\n",
    "            image = transform(self.test[i][0])\n",
    "            label = torch.tensor(self.test[i][1])\n",
    "            self.test[i] = [image,label]\n",
    "        print('Data has been processed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3f57817-58f8-4272-a61a-a1fec70f49c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been loaded\n",
      "Data has been processed\n"
     ]
    }
   ],
   "source": [
    "weeds = WeedsDataset(labels_dir,img_dir,transform)\n",
    "weeds.__loaddata__()\n",
    "weeds.__apply__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c2ed7446-f62b-46ee-8445-45fcccf69ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(weeds.counts)\n",
    "#print(weeds.classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a69f8f-5cff-46ae-9a40-de0b5ea68ae4",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5de1d5ec-6cf4-42cc-bb79-da40c3812083",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(dataset, current_index, batch):\n",
    "    images,labels = zip(*dataset[current_index:current_index+batch])\n",
    "    return torch.stack(images, dim = 0).to(device), torch.stack(labels).to(device)\n",
    "    \n",
    "def train_one_epoch(model, dataset, batch_size):\n",
    "    random.shuffle(dataset.train)\n",
    "    batches = math.floor(len(dataset.train)/batch_size)\n",
    "    current_index = 0\n",
    "    running_loss = 0\n",
    "\n",
    "    for i in range(batches):\n",
    "        inputs,labels = get_batch(dataset.train, current_index, batch_size)\n",
    "        current_index += batch_size\n",
    "        optimizer.zero_grad(set_to_none=True)\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.cpu().item()\n",
    "\n",
    "    remainder = len(dataset.train)%batch_size\n",
    "    if remainder != 0:\n",
    "        inputs,labels = get_batch(dataset.train, current_index, remainder)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.cpu().item()\n",
    "        batches += 1\n",
    "    \n",
    "    return running_loss/batches\n",
    "\n",
    "def validate(model, dataset, batch_size):\n",
    "    batches = math.floor(len(dataset.valid)/batch_size)\n",
    "    current_index = 0\n",
    "    running_loss = 0\n",
    "    \n",
    "    for i in range(batches):\n",
    "        inputs,labels = get_batch(dataset.valid, current_index, batch_size)\n",
    "        current_index += batch_size\n",
    "        output = model(inputs)\n",
    "        running_loss += loss_fn(output, labels).cpu().item()\n",
    "\n",
    "    remainder = len(dataset.valid)%batch_size\n",
    "    if remainder != 0:\n",
    "        inputs,labels = get_batch(dataset.valid, current_index, remainder)\n",
    "        output = model(inputs)\n",
    "        running_loss += loss_fn(output, labels).cpu().item()\n",
    "        batches += 1\n",
    "    \n",
    "    return running_loss/batches\n",
    "\n",
    "def train(epochs, model, dataset, batch_size, folder_name, epoch_number, save, record):\n",
    "    best_vloss = 1000\n",
    "    current_vloss = 0\n",
    "    epoch_counter = epoch_number + 1\n",
    "    start = time.perf_counter()\n",
    "    \n",
    "    if not os.path.exists('{}\\{}'.format(model_path,folder_name)):\n",
    "        os.makedirs('{}\\{}'.format(model_path,folder_name))\n",
    "        \n",
    "    for epoch in range(epochs):\n",
    "        print('EPOCH {}:'.format(epoch_counter))\n",
    "        model.train()\n",
    "        avg_loss = train_one_epoch(model, dataset, batch_size)\n",
    "        \n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            current_vloss = validate(model, dataset, batch_size)\n",
    "\n",
    "        print('LOSS train {} valid {}'.format(avg_loss, current_vloss))\n",
    "        if current_vloss <= best_vloss:\n",
    "                best_vloss = current_vloss\n",
    "                print('New best validation loss')\n",
    "\n",
    "        if epoch_counter - epoch_number > epochs - save:\n",
    "            path = '{}\\\\{}\\\\model_{}'.format(model_path, folder_name, epoch_counter)\n",
    "            torch.save(model.state_dict(), path)\n",
    "\n",
    "        record.append([epoch_counter,avg_loss,current_vloss])\n",
    "        epoch_counter += 1\n",
    "\n",
    "    end = time.perf_counter()\n",
    "    print('Average time taken per epoch is {}s'.format((end - start)/epochs))\n",
    "    return\n",
    "\n",
    "def compute_weights(dataset):\n",
    "    n_samples = len(dataset.train)\n",
    "    n_classes = len(dataset.classes)\n",
    "    weights = torch.zeros(n_classes)\n",
    "    dict = dataset.counts['train']\n",
    "    for i in range(n_classes):\n",
    "        weight = n_samples/(n_classes*dict[i])\n",
    "        weights[i] = weight\n",
    "    return weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f4c59db-fa15-49b9-9fdb-8d99ae183014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formula for F1: (2 * FP) / (2 * TP + FP + FN) OR 2 * (Precision * Recall) / (Precision + Recall)\n",
    "# Formula for Precision: TP / (TP + FP)\n",
    "# Formula for Recall: TP / (TP + FN)\n",
    "def metrics(TP,FP,FN):\n",
    "    if TP > 0:\n",
    "        precision = TP / (TP + FP)\n",
    "        recall = TP / (TP + FN)\n",
    "        F1  = TP / (TP + 0.5 * (FP + FN))\n",
    "    else:\n",
    "        precision = 0\n",
    "        recall = 0\n",
    "        F1  = 0\n",
    "    return precision, recall, F1\n",
    "    \n",
    "# Use weeds.dataset for dataset\n",
    "def evaluate(model, dataset, batch_size, classes):\n",
    "    start = time.perf_counter()\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    batches = math.floor(len(dataset) / batch_size)\n",
    "    current_index = 0\n",
    "    model.eval()\n",
    "    \n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(batches):\n",
    "        inputs, labels = get_batch(dataset, current_index, batch_size)\n",
    "        current_index += batch_size\n",
    "        prediction = torch.argmax(model(inputs),dim = 1)\n",
    "        \n",
    "        correct += sum(prediction == labels).item()\n",
    "        total += batch_size\n",
    "\n",
    "        all_preds.extend(prediction.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    remainder = len(dataset) % batch_size\n",
    "    if remainder != 0:\n",
    "        inputs, labels = get_batch(dataset, current_index, remainder)\n",
    "        prediction = torch.argmax(model(inputs),dim = 1)\n",
    "        \n",
    "        correct += sum(prediction == labels).item()\n",
    "        total += remainder\n",
    "\n",
    "        all_preds.extend(prediction.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "\n",
    "    # Compute Metrics for individual classes\n",
    "    num_classes = len(classes) \n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds, labels=np.arange(num_classes))\n",
    "    print(conf_matrix)\n",
    "\n",
    "    for i in range(num_classes):\n",
    "        TP = conf_matrix[i, i]  # True Positives\n",
    "        FP = np.sum(conf_matrix[:, i]) - TP  # False Positives\n",
    "        FN = np.sum(conf_matrix[i, :]) - TP  # False Negatives\n",
    "        precision,recall,F1 = metrics(TP, FP, FN)\n",
    "        print(f\"Precision for class {classes[i]}: {precision:.4f}\")\n",
    "        print(f\"Recall for class {classes[i]}: {recall:.4f}\")\n",
    "        print(f\"F1-score for class {classes[i]}: {F1:.4f}\")\n",
    "    print('Total Accuracy is {}%'.format(accuracy))\n",
    "    \n",
    "    end = time.perf_counter()\n",
    "    print('Time taken is {}'.format(end - start))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178bc7f8-0bb6-4382-8c1a-d56ee4ee55a6",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d4e73bd1-b4a4-43c3-b10c-6a3d6f5ddf27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.7066, 1.8397, 1.8639, 1.8888, 1.8639, 1.9167, 1.8441, 1.8865, 0.2140])\n"
     ]
    }
   ],
   "source": [
    "weights = compute_weights(weeds)\n",
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3260b971-13f4-41e2-b280-4c9269430412",
   "metadata": {},
   "outputs": [],
   "source": [
    "record = [['Epoch','Training loss','Validation loss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e67317bd-0e07-4a2a-8528-b265986b6ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss(weight=weights).to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.6, weight_decay = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "43a4c755-bb70-45b7-bd49-e8e0b32d4ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1:\n",
      "LOSS train 1.00493153789314 valid 0.5039573592149605\n",
      "New best validation loss\n",
      "EPOCH 2:\n",
      "LOSS train 0.5217553137201313 valid 0.3526537158857968\n",
      "New best validation loss\n",
      "EPOCH 3:\n",
      "LOSS train 0.41513340881919963 valid 0.26030538894109806\n",
      "New best validation loss\n",
      "EPOCH 4:\n",
      "LOSS train 0.36448889929099243 valid 0.23041003247943975\n",
      "New best validation loss\n",
      "EPOCH 5:\n",
      "LOSS train 0.3117625881624618 valid 0.1967321124117253\n",
      "New best validation loss\n",
      "EPOCH 6:\n",
      "LOSS train 0.27295536753907 valid 0.1972112844429784\n",
      "EPOCH 7:\n",
      "LOSS train 0.24587740382574483 valid 0.1546279796383391\n",
      "New best validation loss\n",
      "EPOCH 8:\n",
      "LOSS train 0.22237506148662634 valid 0.1616718540346976\n",
      "EPOCH 9:\n",
      "LOSS train 0.21099097887951507 valid 0.1537213812234922\n",
      "New best validation loss\n",
      "EPOCH 10:\n",
      "LOSS train 0.19477486335403213 valid 0.14267908309791552\n",
      "New best validation loss\n",
      "EPOCH 11:\n",
      "LOSS train 0.18178888449118308 valid 0.1581050243733798\n",
      "EPOCH 12:\n",
      "LOSS train 0.1698375968501865 valid 0.14004929144314285\n",
      "New best validation loss\n",
      "EPOCH 13:\n",
      "LOSS train 0.16081007640824774 valid 0.16575304618484135\n",
      "EPOCH 14:\n",
      "LOSS train 0.14889375477674271 valid 0.12797430411407376\n",
      "New best validation loss\n",
      "EPOCH 15:\n",
      "LOSS train 0.14674805198263624 valid 0.14482233629135763\n",
      "EPOCH 16:\n",
      "LOSS train 0.13870979354311005 valid 0.14306109414388568\n",
      "EPOCH 17:\n",
      "LOSS train 0.13120948105384406 valid 0.13470971870030893\n",
      "EPOCH 18:\n",
      "LOSS train 0.12039645199267078 valid 0.13077727349285603\n",
      "EPOCH 19:\n",
      "LOSS train 0.1158983697499023 valid 0.11906225052741119\n",
      "New best validation loss\n",
      "EPOCH 20:\n",
      "LOSS train 0.11259564816252761 valid 0.12877885432187783\n",
      "EPOCH 21:\n",
      "LOSS train 0.10862810866173349 valid 0.12896244683484467\n",
      "EPOCH 22:\n",
      "LOSS train 0.10023962248892501 valid 0.11809814421033835\n",
      "New best validation loss\n",
      "EPOCH 23:\n",
      "LOSS train 0.10233366571923187 valid 0.13631780236028135\n",
      "EPOCH 24:\n",
      "LOSS train 0.09537022976564719 valid 0.1786832039469411\n",
      "EPOCH 25:\n",
      "LOSS train 0.09146057685480176 valid 0.15152174285099984\n",
      "EPOCH 26:\n",
      "LOSS train 0.09287370555227467 valid 0.14915780120497665\n",
      "EPOCH 27:\n",
      "LOSS train 0.08684242622477124 valid 0.13182486201068228\n",
      "EPOCH 28:\n",
      "LOSS train 0.08522041412060422 valid 0.15967774574676433\n",
      "EPOCH 29:\n",
      "LOSS train 0.0857414790271877 valid 0.12241451872485075\n",
      "EPOCH 30:\n",
      "LOSS train 0.08544244491385507 valid 0.138397075954067\n",
      "Average time taken per epoch is 121.1421716400005s\n"
     ]
    }
   ],
   "source": [
    "train(30,model,weeds,30,'swin1',0,30,record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec87d193-31f6-424a-a46d-bc8d019d7114",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(model_path,'swin1','model_22')\n",
    "model.load_state_dict(torch.load(path, weights_only = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "37e20553-b5b3-41b3-b929-0c1939e23e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 23:\n",
      "LOSS train 0.0791582308219281 valid 0.12440417118477083\n",
      "New best validation loss\n",
      "EPOCH 24:\n",
      "LOSS train 0.07315790976624043 valid 0.11695349175222534\n",
      "New best validation loss\n",
      "EPOCH 25:\n",
      "LOSS train 0.07690642252529531 valid 0.1277459480314342\n",
      "EPOCH 26:\n",
      "LOSS train 0.07319271830191643 valid 0.12677410944420212\n",
      "EPOCH 27:\n",
      "LOSS train 0.06622254528001557 valid 0.13365860286827783\n",
      "EPOCH 28:\n",
      "LOSS train 0.06654792815045259 valid 0.12906371196830582\n",
      "EPOCH 29:\n",
      "LOSS train 0.06710689386681452 valid 0.13043824627490366\n",
      "EPOCH 30:\n",
      "LOSS train 0.06159922121764745 valid 0.1308718815300874\n",
      "EPOCH 31:\n",
      "LOSS train 0.0626493090589439 valid 0.13349512409985112\n",
      "EPOCH 32:\n",
      "LOSS train 0.06317026793372935 valid 0.12088610998047042\n",
      "EPOCH 33:\n",
      "LOSS train 0.059206542409896624 valid 0.13173201702183934\n",
      "EPOCH 34:\n",
      "LOSS train 0.06160525252701808 valid 0.13098411184984213\n",
      "EPOCH 35:\n",
      "LOSS train 0.054729109976928765 valid 0.1361473535450957\n",
      "EPOCH 36:\n",
      "LOSS train 0.05555839695110448 valid 0.126241507851203\n",
      "EPOCH 37:\n",
      "LOSS train 0.05881070941078379 valid 0.1449378957607886\n",
      "EPOCH 38:\n",
      "LOSS train 0.05477957696640441 valid 0.13614920952102816\n",
      "EPOCH 39:\n",
      "LOSS train 0.054052474870078755 valid 0.12971223784231786\n",
      "EPOCH 40:\n",
      "LOSS train 0.055847228425881495 valid 0.14236377543445194\n",
      "Average time taken per epoch is 124.85061168888771s\n"
     ]
    }
   ],
   "source": [
    "record = record[:23]\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = 0.004, momentum = 0.6, weight_decay = 0.00001)\n",
    "train(18,model,weeds,30,'swin1',22,18,record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "da0da4d3-c693-44a4-a518-397a5ed8de71",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(record_path,'swin1.csv'), 'w', newline='') as csvAP:\n",
    "    writer = csv.writer(csvAP)\n",
    "    writer.writerows(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3c3a63-5626-4bc8-b719-4fe8d7fe6ff6",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30acc7cb-f14b-4672-b251-5dd509b4c870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.path.join(model_path,'swin1','model_24')\n",
    "model.load_state_dict(torch.load(path, weights_only = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63e4f4bb-1a7d-47f1-b2a2-3b58a8d0f313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 89   4   0   0   0   2   0   3   2]\n",
      " [  0 100   0   0   0   0   0   2   1]\n",
      " [  0   0 118   0   1   0   0   0   1]\n",
      " [  1   0   1  89   0   0   0   0   2]\n",
      " [  0   0   1   0 101   0   0   0   0]\n",
      " [  1   0   0   0   0 107   0   0   0]\n",
      " [  0   0   0   0   0   0 108   0   2]\n",
      " [  2   0   0   0   0   0   0 113   4]\n",
      " [  3   6   2   6   5   8   3   3 860]]\n",
      "Precision for class Chinee apple: 0.9271\n",
      "Recall for class Chinee apple: 0.8900\n",
      "F1-score for class Chinee apple: 0.9082\n",
      "Precision for class Lantana: 0.9091\n",
      "Recall for class Lantana: 0.9709\n",
      "F1-score for class Lantana: 0.9390\n",
      "Precision for class Parkinsonia: 0.9672\n",
      "Recall for class Parkinsonia: 0.9833\n",
      "F1-score for class Parkinsonia: 0.9752\n",
      "Precision for class Parthenium: 0.9368\n",
      "Recall for class Parthenium: 0.9570\n",
      "F1-score for class Parthenium: 0.9468\n",
      "Precision for class Prickly acacia: 0.9439\n",
      "Recall for class Prickly acacia: 0.9902\n",
      "F1-score for class Prickly acacia: 0.9665\n",
      "Precision for class Rubber vine: 0.9145\n",
      "Recall for class Rubber vine: 0.9907\n",
      "F1-score for class Rubber vine: 0.9511\n",
      "Precision for class Siam weed: 0.9730\n",
      "Recall for class Siam weed: 0.9818\n",
      "F1-score for class Siam weed: 0.9774\n",
      "Precision for class Snake weed: 0.9339\n",
      "Recall for class Snake weed: 0.9496\n",
      "F1-score for class Snake weed: 0.9417\n",
      "Precision for class Negative: 0.9862\n",
      "Recall for class Negative: 0.9598\n",
      "F1-score for class Negative: 0.9729\n",
      "Total Accuracy is 96.23072529982866%\n",
      "Time taken is 7.344480700005079\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    evaluate(model,weeds.test,30,weeds.classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ff1dd8-06ec-492b-8977-4ec91b435744",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    evaluate(model,weeds.valid,30,weeds.classes)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9fc68b3a-28cc-4ee1-a834-e1fb3c73d553",
   "metadata": {},
   "source": [
    "with torch.no_grad():\n",
    "    evaluate(model,weeds.train,30,weeds.classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
